{
    "batch_size": 64,
    "block_size": 256,
    "max_iters": 1,
    "eval_interval": 50,
    "learning_rate": 0.0003,
    "eval_iters": 200,
    "n_embd": 384,
    "n_head": 3,
    "n_layer": 3,
    "dropout": 0.2,
    "n_hidden_layers": 1,
    "hidden_size": 256,
    "original_params_million": 5.468993,
    "mlp_attention_params_million": 6.061121,
    "train_loss": [
        4.253289222717285
    ],
    "val_loss": [
        4.247520923614502
    ],
    "mlp_attention_train_loss": [
        4.175312519073486
    ],
    "mlp_attention_val_loss": [
        4.176568031311035
    ],
    "epochs": [
        0
    ]
}